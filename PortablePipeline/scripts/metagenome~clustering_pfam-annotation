#!/bin/bash

explanation='
Clustering by abundance patterns and annotating species by aggregating Pfam domains present in each cluster.
Docker must be installed.
'
inputdef='
input_1::Assembled contigs (FASTA):*.fa,*.fasta
input_2:directory option:paired-end FASTQ(.gz):*.fastq,*.fq,*.fastq.gz,*.fq.gz
input_3:directory option:single-end FASTQ(.gz):*.fastq,*.fq,*.fastq.gz,*.fq.gz
'
optiondef='
opt_c:cpu threads:16
opt_m:memory limit (GB):300
opt_r:clustering threshold:0.85
'
runcmd="$0 -c #opt_c# -m #opt_m# #input_1# #input_2# #input_3#"

export IM_SAMTOOLS="c2997108/centos7:1-trinity_2.8.5-kallisto_0.46.0-blast_2.9.0-trinotate-3.1.1-R_6-kegg_4"
export IM_AWK="c2997108/centos6:2-bwa-0.7.17-r1198-dirty"
export IM_BWA="c2997108/centos6:2-bwa-0.7.17-r1198-dirty"
export IM_R="c2997108/centos6:2-bwa-0.7.17-r1198-dirty"
export IM_COR="c2997108/centos7:metacor3"
export IM_MERGE="c2997108/centos7:3-java"
source $(dirname `readlink -f $0 || echo $0`)/common.sh

set -eux
set -o pipefail


ref=$input_1
DO_BWA bwa index $ref
DO_SAMTOOLS samtools faidx $ref

if [ "$input_2" = "" ] && [ "$input_3" = "" ]; then echo No input FASTQ; exit 1; fi
(if [ "$input_2" != "" ]; then
  for i in `find $input_2/ |egrep '(_R1.*|_1)[.]f(ast|)q(|[.]gz)$' || true`; do
  if [ `echo $i|egrep "_1[.]f(ast|)q(|[.]gz)$"|wc -l||true` = 1 ]; then
   j=`echo $i|sed 's/_1[.]f\(ast\|\)q/_2.f\1q/'`;
  elif [ `echo $i|egrep "_R1"|wc -l||true` = 1 ]; then
   j=`echo $i|sed 's/_R1/_R2/'`;
  else
   j=none
  fi
  i2=`basename $i`
  if [ -e "$j" ]; then
   samplename=`basename $i|sed 's/_1[.]f.*//'|sed 's/_R1.*//'`;
   echo "$ENV_BWA bwa mem -t $N_CPU -M -R \'@RG\\\tID:$samplename\\\tSM:$samplename\\\tLB:library\' \'$ref\' \'$i\' \'$j\' > \'$i2.sam\'"
  else
   samplename=`basename $i|sed 's/[.]f\(ast\|\)q.*//'`;
   echo "$ENV_BWA bwa mem -t $N_CPU -M -R \'@RG\\\tID:$samplename\\\tSM:$samplename\\\tLB:library\' \'$ref\' \'$i\' > \'$i2.sam\'"
  fi
 done
fi
if [ "$input_3" != "" ]; then
 for i in `find $input_3/ |egrep '[.]f(ast|)q(|[.]gz)$' || true`; do
  i2=`basename $i`
  samplename=`basename $i|sed 's/[.]f\(ast\|\)q.*//'`;
  echo "$ENV_BWA bwa mem -t $N_CPU -M -R \'@RG\\\tID:$samplename\\\tSM:$samplename\\\tLB:library\' \'$ref\' \'$i\' > \'$i2.sam\'"
 done
fi
) | DOPARALLEL

WAITPARALLEL

cat << 'EOF' > run-count.sh
input="$1"
ref="$2"
N_CPU="$3"
outname="$input"
cat "$input"|grep -v "^@"|awk -F'\t' '{a=$6; gsub(/[0-9]+[^0-9M]/,"",a); split(a,arr,"M"); map=0; for(i in arr){map+=arr[i]}; b=$6; gsub(/[^0-9]/,",",b); split(b,arr,","); total=0; for(i in arr){total+=arr[i]}; for(i=12;i<=NF;i++){if($i~"^MD:Z:"){c=$i; gsub(/^MD:Z:/,"",c); gsub(/[0-9]/,"",c); if((map-length(c))/total>=0.8){print map"\t"$0}}}}' > "$outname".sam2
awk -F'\t' 'FILENAME==ARGV[1]{len[$1]=$2} FILENAME==ARGV[2]{a[$4]+=$1} END{for(i in a){print i"\t"a[i]/len[i]"\t"a[i]"\t"len[i]}}' "$ref".fai "$outname".sam2 > "$outname".cov
(samtools view -SH "$input"; cut -f 2- "$outname".sam2)|samtools view -Sb -@ $N_CPU - | samtools sort -T "$outname".clean -@ $N_CPU -o "$outname".clean.bam
(echo -e 'id\tcoverage\tmapped bases\tlength'; cat "$outname".cov) > "$outname".coverage.txt

rm -f "$input" "$outname".sam2 "$outname".cov
samtools index "$outname".clean.bam

EOF

for i in *.sam; do
 echo "$ENV_SAMTOOLS bash run-count.sh \'$i\' \'$ref\' \'$N_CPU\'"
done | DOPARALLEL
WAITPARALLEL

for i in *.sam.coverage.txt; do
 echo -e 'id\t'`basename "$i" .sam.coverage.txt` > "$i".input
 tail -n+2 "$i"|cut -f 1-2 >> "$i".input
done
DO_MERGE merge_table.pl -k *.coverage.txt.input|sed 's/\t\t/\t0\t/g; s/\t\t/\t0\t/g; s/\t$/\t0/' > all.coverage.txt
rm -f *.coverage.txt.input run-count.sh

echo "ln -s /ddca2/* /ddca/; /ddca/app/jdk1.8.0_05/bin/java -Xmx${N_MEM_G}G -cp /ddca/download/ddca/bin/ corclust.Clustering all.coverage.txt $opt_r 20 > temp.txt" > run.temp.sh
DO_COR bash run.temp.sh

echo cluster_id > cluster.txt
cut -f 2 temp.txt >> cluster.txt
paste all.coverage.txt cluster.txt > all.coverage.cluster.txt
rm -f temp.txt all.coverage.txt cluster.txt *.coverage.txt

echo "ln -s /ddca2/* /ddca/; /ddca/tool/exonerate-2.2.0-x86_64/bin/fastasplit $ref . -c $N_CPU" > run.temp.sh
DO_COR bash run.temp.sh

base=`basename ${ref}`
echo 'i=$1; ln -s /ddca2/* /ddca/; /ddca/tool/EMBOSS-6.6.0/bin/transeq -frame 6 $i -outseq $i.aa' > run.temp.sh
for i in `ls ${base}_chunk_*|grep -v [.]aa$|grep -v [.]pfam`; do DO_COR bash run.temp.sh "$i" ; done
echo 'i=$1; ln -s /ddca2/* /ddca/; export PATH=$PATH:/ddca/tool/hmmer-3.1b2/bin;
 PERL5LIB=/ddca/download/PfamScan:/perl5/lib/perl5 /ddca/download/PfamScan/pfam_scan.pl -fasta $i -dir /ddca/download/PfamScan -cpu 1 > $i.pfam' > run.temp.sh
for i in ${base}_chunk_*.aa; do DO_COR bash run.temp.sh "$i" & done
wait

cat ${base}_chunk_*.aa.pfam |grep -v "^#" |sed '/^$/d' > all.pfam
cat all.pfam |awk '{print $1"\t"$6}'|sed 's/_.\t/\t/' > all.pfam.tsv
DO_AWK awk -F'\t' '
 FILENAME==ARGV[1]{cluster[$1]=$NF; a[$NF]++}
 FILENAME==ARGV[2]{b[$2]++; res[cluster[$1]][$2]++}
 END{ORS="\t"; print "id"; for(j in a){print j}; ORS="\n"; print ""; for(i in b){ORS="\t"; print i; for(j in a){print res[j][i]; delete res[j][i]}; ORS="\n"; print ""}}
' all.coverage.cluster.txt all.pfam.tsv |sed 's/\t$//; s/\t\t/\t0\t/g; s/\t\t/\t0\t/g; s/\t$/\t0/' > all.pfam.tsv2
rm -f ${base}_chunk_* all.pfam all.pfam.tsv cluster.txt


cat all.pfam.tsv2|tail -n+2|awk -F'\t' '{for(i=2;i<=NF;i++){a[i]+=$i}; n=NF} END{for(i=2; i<=n; i++){if(a[i]==0){print i}}}' > all.pfam.tsv2.zero
awk -F'\t' 'FILENAME==ARGV[1]{a[$1]++} FILENAME==ARGV[2]{ORS="\t"; print $1; for(i=2;i<=NF;i++){if(a[i]==0){print $i}}; ORS="\n"; print ""}' all.pfam.tsv2.zero all.pfam.tsv2 |
 sed 's/\t$//' > all.pfam.tsv4

cat << 'EOF' > run-pfamadd.sh
ln -s /ddca2/* /ddca/
i=/ddca/db/pfam/pfam.tsv
j=all.pfam.tsv4
m=`head -n 1 $i|awk -F'\t' '{print NF}'`;
awk -F'\t' 'BEGIN{str=""; for(i=1;i<'$m';i++){str=str"\t0"}} FILENAME==ARGV[1]{a[$1]=$0; b[$1]=1}
 FILENAME==ARGV[2]{if(b[$1]==1){b[$1]=0; print a[$1]"\t"$0}else{print $1""str"\t"$0}; n=NF}
 END{str=""; for(i=1;i<n;i++){str=str"\t0"}; for(i in b){if(b[i]==1){print a[i]"\t"str}}}'  $i $j | cut -f 1-$m,`expr $m + 2`- > all.tsv
echo $m > temp.m
EOF

DO_COR bash run-pfamadd.sh
rm -f all.pfam.tsv2.zero all.pfam.tsv2 run-pfamadd.sh

perl -e '
@a=();
$n=0;
open(IN, $ARGV[0]);
while($line=<IN>){
 $line=~s/\n//;
 $n++;
 $a[$n]=$line;
};
my @F = split(/\t/,$a[1]);
$m=$#F;
@b=();
for($i=1;$i<=$n;$i++){$b[$i]=0};
for($j=0; $j<=$m-1; $j++){
for($i=1;$i<=$n;$i++){$l=index($a[$i],"\t",$b[$i]); print substr($a[$i], $b[$i], $l - $b[$i])."\t"; $b[$i]=$l+1 };
print "\n";
}
for($i=1;$i<=$n;$i++){print substr($a[$i], $b[$i])."\t"}; print "\n";
' all.tsv |sed 's/\t$//' > all.tsv2
#n=`head -n 1 /ddca/db/pfam/pfam.tsv |awk -F'\t' '{print NF}'`
n=`cat temp.m`
m=`expr $n + 1`
head -n $n all.tsv2 > pfam.tsv
tail -n+$m all.tsv2 > all.tsv3

echo "ln -s /ddca2/* /ddca/;
java -Xmx${N_MEM_G}G -classpath /ddca/download/ddca/bin/ corclust/Pfamclustering pfam.tsv all.tsv3 > pfam.ann.tsv
cut -f 2- pfam.ann.tsv > all.tsv.cluster" > run.temp.sh
cat << 'EOF' >> run.temp.sh
awk -F'\t' '
 FILENAME==ARGV[1]{name[$1]=$2}
 FILENAME==ARGV[2]{
  ORS="\t"; print $1; for(i=2;i<=11;i++){split($i,arr,":"); str=arr[1]; for(j=2;j<length(arr);j++){str=str":"arr[j]};
   if(name[str]==""){split(str,arr,"."); str=arr[1]; for(j=2;j<length(arr);j++){str=str"."arr[j]}}; print name[str]";"str":"arr[length(arr)]};
  ORS="\n"; print ""}' /ddca/db/pfam/pfam.tsv.taxid.name2 all.tsv.cluster > all.tsv.cluster2

EOF

DO_COR bash run.temp.sh

awk -F'\t' 'FILENAME==ARGV[1]{len[$1]=$2} FILENAME==ARGV[2]{size[$NF]+=len[$1]} END{for(i in size){print i"\t"size[i]}}' "$ref".fai all.coverage.cluster.txt  > cluster.size
n=`head -n 1 all.coverage.cluster.txt| awk -F'\t' '{for(i=1;i<=NF;i++){if($i~"^cluster_id$"){print i}}}'|head -n 1`
awk -F'\t' 'FILENAME==ARGV[1]{size[$1]=$2} FILENAME==ARGV[2]{a[$1]=$2; b[$1]=$3; c[$1]=$4} FILENAME==ARGV[3]{if(n==0){print $0"\tcluster size\tPfam annotation 1\tPfam annotation 2\tPfam annotation 3"; n++}else{print $0"\t"size[$'$n']"\t"a[$'$n']"\t"b[$'$n']"\t"c[$'$n']}}' cluster.size all.tsv.cluster2 all.coverage.cluster.txt > OUTPUT.tsv
#cp all.pfam OUTPUT_0001_0001/file.tsv
rm -f all.tsv all.tsv2 pfam.tsv all.coverage.cluster.txt temp.m all.tsv3 run.temp.sh pfam.ann.tsv all.tsv.cluster2 cluster.size




post_processing
#<option detail>
#<opt_b>
Algorithm options:

       -t INT        number of threads [1]
       -k INT        minimum seed length [19]
       -w INT        band width for banded alignment [100]
       -d INT        off-diagonal X-dropoff [100]
       -r FLOAT      look for internal seeds inside a seed longer than {-k} * FLOAT [1.5]
       -y INT        seed occurrence for the 3rd round seeding [20]
       -c INT        skip seeds with more than INT occurrences [500]
       -D FLOAT      drop chains shorter than FLOAT fraction of the longest overlapping chain [0.50]
       -W INT        discard a chain if seeded bases shorter than INT [0]
       -m INT        perform at most INT rounds of mate rescues for each read [50]
       -S            skip mate rescue
       -P            skip pairing; mate rescue performed unless -S also in use

Scoring options:

       -A INT        score for a sequence match, which scales options -TdBOELU unless overridden [1]
       -B INT        penalty for a mismatch [4]
       -O INT[,INT]  gap open penalties for deletions and insertions [6,6]
       -E INT[,INT]  gap extension penalty; a gap of size k cost '{-O} + {-E}*k' [1,1]
       -L INT[,INT]  penalty for 5'- and 3'-end clipping [5,5]
       -U INT        penalty for an unpaired read pair [17]

       -x STR        read type. Setting -x changes multiple parameters unless overriden [null]
                     pacbio: -k17 -W40 -r10 -A1 -B1 -O1 -E1 -L0  (PacBio reads to ref)
                     ont2d: -k14 -W20 -r10 -A1 -B1 -O1 -E1 -L0  (Oxford Nanopore 2D-reads to ref)
                     intractg: -B9 -O16 -L5  (intra-species contigs to ref)

Input/output options:

       -p            smart pairing (ignoring in2.fq)
       -R STR        read group header line such as '@RG\tID:foo\tSM:bar' [null]
       -H STR/FILE   insert STR to header if it starts with @; or insert lines in FILE [null]
       -j            treat ALT contigs as part of the primary assembly (i.e. ignore <idxbase>.alt file)

       -v INT        verbose level: 1=error, 2=warning, 3=message, 4+=debugging [3]
       -T INT        minimum score to output [30]
       -h INT[,INT]  if there are <INT hits with score >80% of the max score, output all in XA [5,200]
       -a            output all alignments for SE or unpaired PE
       -C            append FASTA/FASTQ comment to SAM output
       -V            output the reference FASTA header in the XR tag
       -Y            use soft clipping for supplementary alignments
       -M            mark shorter split hits as secondary

       -I FLOAT[,FLOAT[,INT[,INT]]]
                     specify the mean, standard deviation (10% of the mean if absent), max
                     (4 sigma from the mean if absent) and min of the insert size distribution.
                     FR orientation only. [inferred]

Note: Please read the man page for detailed description of the command line and options.

#</opt_b>
#</option detail>

