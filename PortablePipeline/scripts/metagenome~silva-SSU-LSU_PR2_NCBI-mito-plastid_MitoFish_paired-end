#!/bin/bash

explanation='
Meta-barcoding metagenome analysis pipeline
using SILVA SSU+LSU, PR2 database, NCBI mito & plastid database and MitoFish database
'
inputdef='
input_1:directory:paired-end FASTQ(.gz):*.fastq,*.fq,*.fastq.gz,*.fq.gz,*.fasta,*.fa,*.fasta.gz,*.fa.gz
'
optiondef='
opt_c:cpu threads:8
opt_m:memory limit (GB):32
opt_b:blast option:
opt_d:bit score threshold:100
opt_a:Alignment percentage of aligned reads (%):0
opt_l:Minimum alignment length (bp):100
opt_i:Minimum alignment identity (%):90
opt_t:Score from top of BLAST hits used in LCA:0.95
opt_s:Divide FASTQ by this number of reads:10000
opt_g:read number for normalization:10000
'
runcmd="$0 -c #opt_c# -m #opt_m# -b #opt_b# -d #opt_d# -a #opt_a# -l #opt_l# -i #opt_i# -t #opt_t# -s #opt_s# -g #opt_g# #input_1#"

export IM_PR2="c2997108/centos7:2-blast-taxid-2-KronaTools-2.7-pr2-mito-silva-3"
export IM_BASE="c2997108/centos7:3-java"
export IM_SEQKIT="quay.io/biocontainers/seqkit:2.6.1--h9ee0642_0"

source $(dirname `readlink -f $0 || echo $0`)/common.sh

set -eux
set -o pipefail


cat << 'EOS' > run-split.sh
set -ex
i="$1"
nmaxreads="$2"
seqkit stats -T "$i" > "$i".stats
n=`tail -n 1 "$i".stats|awk -F'\t' -v nmaxreads=$nmaxreads '{print int($4/nmaxreads)}'`
#基本的にはnmaxreadsリードずつに分割するけど、1万個以上に分割しそうなときは1万個までに分割するための措置
if [ $n -lt 10000 ]; then nreads=$nmaxreads; else nreads=`tail -n 1 "$i".stats|awk -F'\t' '{print int($4/10000)}'`; fi
j=`basename "$i"|sed 's/q[.]gz$/a.gz/; s/q$/a/'`
if [ `echo $i|grep -E "_1[.]f(ast|)q([.]gz|)$"|wc -l||true` = 1 ]; then
 i2=`echo $i|sed 's/_1[.]f\(ast\|\)\(q\|a\)\([.]gz\|\)$/_2.f\1\2\3/'`;
 j2=`echo $j|sed 's/_1[.]f\(ast\|\)a\([.]gz\|\)$/_2.f\1a\2/'`;
else
 i2=`echo $i|sed 's/_R1/_R2/'`
 j2=`echo $j|sed 's/_R1/_R2/'`
fi
for k in `echo "$i"|grep -E "[.]f(ast|)q([.]gz|)$"`; do
 seqkit fq2fa -o fq2fa/"$j" "$i"
 seqkit fq2fa -o fq2fa/"$j2" "$i2"
 i=fq2fa/"$j"
 i2=fq2fa/"$j2"
done
seqkit split2 -s $nreads -e .gz -O split/`basename $i` -1 "$i" -2 "$i2"

EOS

mkdir -p fq2fa
(for i in `find "$input_1/"|grep -E "(_R1.*|_1)[.]f(ast|)(a|q)([.]gz|)$"||true`; do
 echo $ENV_SEQKIT bash run-split.sh "$i" "$opt_s"
done)|DOPARALLELONE

WAITPARALLEL

rm -rf fq2fa


cat << 'EOF' > run-count-paired.py
# -*- coding: utf-8 -*-
import sys
import re
args = sys.argv
if len(args) < 5:
  raise Exception('python3 ' + args[0] + ' <file_1.fasta> <file_2.fasta> <file_1.fasta.blast> <file_2.fasta.blast>')

fa1 = open(args[1], 'r')
fa2 = open(args[2], 'r')
fb1 = open(args[3], 'r')
fb2 = open(args[4], 'r')
#fa1 = open('test_1.fa', 'r')
#fa2 = open('test_2.fa', 'r')
#fb1 = open('test_1.fa.blast', 'r')
#fb2 = open('test_2.fa.blast', 'r')

la1 = fa1.readline()
la2 = fa2.readline()
lb1 = fb1.readline()
lb2 = fb2.readline()

old_lb1_1 = ''
old_lb2_1 = ''

while la1:
  if la1[0]=='>':
    if la1[1:].strip().split(' ')[0].split('\t')[0] == re.sub(r'/2$', "/1", la2[1:].strip().split(' ')[0].split('\t')[0]):
      name = la1[1:].strip().split(' ')[0].split('\t')[0]
      name2 = la2[1:].strip().split(' ')[0].split('\t')[0]
      a={}
      n1={}
      n2={}
      if lb1:
        while lb1.strip().split('\t')[0] == name:
          if lb1.strip().split('\t')[1] != old_lb1_1:
            old_lb1_1 = lb1.strip().split('\t')[1]
            if n1.get(old_lb1_1): # for only 1 time addition
              n1[old_lb1_1]+=1
            else:
              n1[old_lb1_1]=1
            if a.get(old_lb1_1) and n1[old_lb1_1] == 1:
              a[old_lb1_1][0]+=float(lb1.strip().split('\t')[11]) #bitscore
              oldalignlen=a[old_lb1_1][1]
              newalignlen=float(lb1.strip().split('\t')[7])-float(lb1.strip().split('\t')[6])+1
              a[old_lb1_1][1]+=newalignlen #alignment length
              a[old_lb1_1][2]=(a[old_lb1_1][2]/100*oldalignlen+float(lb1.strip().split('\t')[2])/100*newalignlen)/(oldalignlen + newalignlen)*100 #identity
            else:
              a[old_lb1_1]=[ float(lb1.strip().split('\t')[11]), #bitscore
                             float(lb1.strip().split('\t')[7])-float(lb1.strip().split('\t')[6])+1, #alignment length
                             float(lb1.strip().split('\t')[2]) ] #identity
          lb1 = fb1.readline()
          if not lb1:
            break
      if lb2:
        while lb2.strip().split('\t')[0] == name2:
          if lb2.strip().split('\t')[1] != old_lb2_1:
            old_lb2_1 = lb2.strip().split('\t')[1]
            if n2.get(old_lb2_1): # for only 1 time addition
              n2[old_lb2_1]+=1
            else:
              n2[old_lb2_1]=1
            if a.get(old_lb2_1) and n2[old_lb2_1] == 1:
              a[old_lb2_1][0]+=float(lb2.strip().split('\t')[11]) #bitscore
              oldalignlen=a[old_lb2_1][1]
              newalignlen=float(lb2.strip().split('\t')[7])-float(lb2.strip().split('\t')[6])+1
              a[old_lb2_1][1]+=newalignlen #alignment length
              a[old_lb2_1][2]=(a[old_lb2_1][2]/100*oldalignlen+float(lb2.strip().split('\t')[2])/100*newalignlen)/(oldalignlen + newalignlen)*100 #identity
            else:
              a[old_lb2_1]=[ float(lb2.strip().split('\t')[11]), #bitscore
                             float(lb2.strip().split('\t')[7])-float(lb2.strip().split('\t')[6])+1, #alignment length
                             float(lb2.strip().split('\t')[2]) ] #identity
          lb2 = fb2.readline()
          if not lb2:
            break
      if len(a) > 0:
        # キーと最初の要素のペアを取得し、最初の要素でソート
        sorted_keys = sorted(a, key=lambda k: a[k][0], reverse=True)
        sorted_data = {key: a[key] for key in sorted_keys}
        for key, value in sorted_data.items():
          print(name+"\t"+key+"\t"+str(value[0])+"\t"+str(value[1])+"\t"+str(value[2]))
    else:
      raise Exception('read name of input1 is different with input2')
  la1 = fa1.readline()
  la2 = fa2.readline()
#  print(not la1)
fa1.close()
fa2.close()
fb1.close()
fb2.close()

EOF


cat << 'EOS' > run-blast.sh
i=$1
bitscore="$2"
top="$3"
blastop="$5"
cpu="$4"
alignpercent="$6" #0
alignlength="$8" #100
identity="$7" #90

ref=/usr/local/blastdb/mergedDB.maskadaptors.fa

set -ex

echo "##count reads"
n0=`zcat "$i"|grep "^>"|wc -l`

j="$i" #split/201205_C5_SUF_0.2um_L1_1.fa.gz/201205_C5_SUF_0.2um_L1_1.part_001.fa.gz

if [ `echo $i|egrep "_1[.]part_[0-9]*[.](fasta|fa)(|[.]gz)$"|wc -l||true` = 1 ]; then #恐らく.gzのみで未圧縮はこの流れではこないけど一応
 i2=`echo $i|sed 's/_1[.]part_\([0-9]*\)[.]\(fasta\|fa\)\(\|[.]gz\)$/_2.part_\1.\2\3/'`;
 j2="$i2"
else
 #i2=`echo $i|sed 's/_R1/_R2/'`
 i2=`echo $i|rev|sed 's/1R_/2R_/'|rev`
 j2="$i2"
fi

echo "##blast"
zcat "$j"|blastn -db $ref -query /dev/stdin -outfmt 6 -out $j.blast -num_threads $cpu $blastop
zcat "$j2"|blastn -db $ref -query /dev/stdin -outfmt 6 -out $j2.blast -num_threads $cpu $blastop

python run-count-paired.py <(zcat $j) <(zcat $j2) $j.blast $j2.blast > $j.all.blast

echo "##filtering"
awk -F'\t' -v bitscore="$bitscore" -v top="$top" -v alignpercent="$alignpercent" -v alignlength="$alignlength" -v identity="$identity" '
 FILENAME==ARGV[1]{split($1,arr," "); len[arr[1]]=$2}
 FILENAME==ARGV[2]{split($1,arr," "); sub("/2$","/1",arr[1]); len2[arr[1]]=$2}
 FILENAME==ARGV[3]{
  if($3>=bitscore&&$5>=identity&&($4>=alignlength)&&($4>=(len[$1]+len2[$1])*alignpercent/100)){
   if(a[$1]==1){
    if($3>=topbit*top&&$5>=identity&&($4>=alignlength)&&($4>=(len[$1]+len2[$1])*alignpercent/100)){print $0}
   }else{
    a[$1]=1; topbit=$12; print $0
   }
  }
 }' <(seqkit fx2tab $j) <(seqkit fx2tab $j2) $j.all.blast > $j.blast.filtered

echo "##determine LCA"
#blast実行時に配列名の最後が「.」の場合削られるなどヒットした配列名が元の名前から変わるので注意
awk -F'\t' 'FILENAME==ARGV[1]{name[$1]=$2} FILENAME==ARGV[2]{print name[$2]"\t"$0}' $ref.path $j.blast.filtered > $j.blast.filtered.name

awk -F'\t' '
function searchLCA(data,  i, j, res, res2, str, n, stopflag){
 for(i in data){
  if(n==0){n=split(i,res,";")}
  else{split(i,res2,";"); for(j in res){if(res[j]!=res2[j]){res[j]=""}}}
 }
 if(res[1]!=""){str=res[1]}
 else{
  #i: taxonomy path
  #葉緑体と植物の18Sは相同性が高いみたいなのでそれが混ざるときは葉緑体を優先させる
  chloroplast=0
  delete datachloro
  for(i in data){
   if(i~"^Bacteria;Cyanobacteria;Cyanobacteriia;Chloroplast;"){chloroplast++; datachloro[i]=1}
  }
  if(chloroplast>0){
   n2=0
   for(i in datachloro){
    if(n2==0){n2=split(i,res,";")}
    else{split(i,res2,";"); for(j in res){if(res[j]!=res2[j]){res[j]=""}}}
   }
  }
 }
 if(res[1]!=""){str=res[1]}
 else{
  str="unknown"; stopflag=1
 };
 for(i=2;i<=n;i++){if(stopflag==0 && res[i]!=""){str=str";"res[i]}else{stopflag=1}}
 return str;
}
{
 if($2!=old){if(old!=""){print searchLCA(data)"\t"oldstr}; delete data; data[$1]=1; old=$2; oldstr=$0}
 else{data[$1]=1}
}
END{if(length(data)>0){print searchLCA(data)"\t"oldstr}}
' $j.blast.filtered.name > $j.blast.filtered.name.lca

awk -F'\t' '{cnt[$1]++} END{PROCINFO["sorted_in"]="@val_num_desc"; for(i in cnt){print i"\t"cnt[i]}}' $j.blast.filtered.name.lca > $j.blast.filtered.name.lca.cnt
awk -F'\t' '{print "root;"$0}' $j.blast.filtered.name.lca.cnt > $j.blast.filtered.name.lca.cnt2
cnt=`awk -F'\t' '{a+=$2} END{if(a==""){a=0}; print a}' $j.blast.filtered.name.lca.cnt`
echo -e "No Hit\t"`expr $n0 - $cnt` >> $j.blast.filtered.name.lca.cnt2

EOS

find split -mindepth 2 -maxdepth 2|grep -E "(_R1.*|_1)[.]part_[0-9]*[.](fasta|fa)[.]gz$"|while read i; do
 echo $ENV_PR2 bash run-blast.sh "$i" "$opt_d" "$opt_t" 1 "'$opt_b'"
done|DOPARALLEL

WAITPARALLEL

mkdir -p result result.temp
for i in split/*; do
 (echo -e "id\t"`basename $i`; awk -F'\t' '{data[$1]+=$2} END{PROCINFO["sorted_in"]="@val_type_desc"; for(i in data){print i"\t"data[i]}}' "$i"/*.cnt2) > result/`basename $i`.tsv
 tail -n+2 result/`basename $i`.tsv|awk -F'\t' '
  {n=split($1,arr,";"); ORS="\t"; print $2; for(i=1;i<n;i++){print arr[i]}; ORS="\n"; print arr[n]}
 ' > result.temp/`basename $i`
done
DO_PR2 /usr/local/KronaTools-2.7/scripts/ImportText.pl result.temp/* -o all.html
rm -rf result.temp

if [ `ls result/*.tsv|wc -l` -gt 1 ]; then
 DO_BASE merge_table.pl -k result/*.tsv|sed 's/\t\t/\t0\t/g; s/\t\t/\t0\t/g; s/\t$/\t0/' > all.counts.txt
else
 cp result/*.tsv all.counts.txt
fi
DO_BASE awk -F'\t' '
 FILENAME==ARGV[1]{if(FNR>1){for(i=2;i<=NF;i++){a[i]+=$i}}}
 FILENAME==ARGV[2]{if(FNR==1){OFS="\t"; for(i=2;i<=NF;i++){$i=$i" (counts per '$opt_g')"; if(a[i]==0){a[i]=1}}; print $0}
                   else{ORS=""; print $1;for(i=2;i<=NF;i++){print "\t"$i/a[i]*'$opt_g'}; print "\n"}}
' all.counts.txt ./all.counts.txt > all.counts.per.$opt_g.txt
DO_BASE java -Xmx1G -jar /usr/local/bin/excel2.jar all.counts.txt all.counts.xlsx
DO_BASE java -Xmx1G -jar /usr/local/bin/excel2.jar all.counts.per.$opt_g.txt all.counts.per.$opt_g.xlsx


post_processing
#<option detail>
#<opt_b>
USAGE
  blastn [-h] [-help] [-import_search_strategy filename]
    [-export_search_strategy filename] [-task task_name] [-db database_name]
    [-dbsize num_letters] [-gilist filename] [-seqidlist filename]
    [-negative_gilist filename] [-entrez_query entrez_query]
    [-db_soft_mask filtering_algorithm] [-db_hard_mask filtering_algorithm]
    [-subject subject_input_file] [-subject_loc range] [-query input_file]
    [-out output_file] [-evalue evalue] [-word_size int_value]
    [-gapopen open_penalty] [-gapextend extend_penalty]
    [-perc_identity float_value] [-qcov_hsp_perc float_value]
    [-max_hsps int_value] [-xdrop_ungap float_value] [-xdrop_gap float_value]
    [-xdrop_gap_final float_value] [-searchsp int_value]
    [-sum_stats bool_value] [-penalty penalty] [-reward reward] [-no_greedy]
    [-min_raw_gapped_score int_value] [-template_type type]
    [-template_length int_value] [-dust DUST_options]
    [-filtering_db filtering_database]
    [-window_masker_taxid window_masker_taxid]
    [-window_masker_db window_masker_db] [-soft_masking soft_masking]
    [-ungapped] [-culling_limit int_value] [-best_hit_overhang float_value]
    [-best_hit_score_edge float_value] [-window_size int_value]
    [-off_diagonal_range int_value] [-use_index boolean] [-index_name string]
    [-lcase_masking] [-query_loc range] [-strand strand] [-parse_deflines]
    [-outfmt format] [-show_gis] [-num_descriptions int_value]
    [-num_alignments int_value] [-line_length line_length] [-html]
    [-max_target_seqs num_sequences] [-num_threads int_value] [-remote]
    [-version]

#</opt_b>
#</option detail>

